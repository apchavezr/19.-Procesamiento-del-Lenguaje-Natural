{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPncnnBLoaoTVxkP7IpnzA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apchavezr/19.-Procesamiento-del-Lenguaje-Natural/blob/main/pipeline_en_scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 2. Clasificación de sentimientos en español.\n",
        "\n",
        "Construcción de un pipeline en scikit-learn que encadena todas las fases: Corpus en bruto → Limpieza → Tokenización → Embeddings (TF-IDF) → Entrenamiento → Validación → Registro de métricas."
      ],
      "metadata": {
        "id": "hF_aeIho7Azt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación del flujo\n",
        "* 1.\tCorpus en bruto → se definen reseñas cortas.\n",
        "* 2.\tLimpieza → minúsculas y eliminación de caracteres no alfabéticos.\n",
        "* 3.\tTokenización y embeddings → TfidfVectorizer convierte los textos en vectores numéricos.\n",
        "* 4.\tEntrenamiento → LogisticRegression aprende a distinguir reseñas positivas y negativas.\n",
        "* 5.\tValidación → classification_report y confusion_matrix registran métricas.\n"
      ],
      "metadata": {
        "id": "T3goHruR54ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTvNcFPd5wEp",
        "outputId": "0b00a0f2-5fde-4864-f15f-c18a60411b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reporte de clasificación:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.50      1.00      0.67         1\n",
            "    positivo       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "Matriz de confusión:\n",
            "\n",
            "[[1 0]\n",
            " [1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de pipeline en scikit-learn para PLN en español\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Corpus en bruto (mini dataset)\n",
        "corpus = [\n",
        "    \"La película fue excelente, muy entretenida y conmovedora\",   # positivo\n",
        "    \"El guion fue aburrido y la actuación muy pobre\",             # negativo\n",
        "    \"Me encantó la fotografía y la música\",                       # positivo\n",
        "    \"La trama fue lenta y predecible\",                            # negativo\n",
        "    \"Un espectáculo visual, realmente impresionante\",             # positivo\n",
        "    \"No me gustó, esperaba mucho más\",                            # negativo\n",
        "]\n",
        "\n",
        "labels = [1, 0, 1, 0, 1, 0]  # 1 = positivo, 0 = negativo\n",
        "\n",
        "# 2. Función de limpieza básica\n",
        "def limpiar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"[^a-záéíóúñü\\s]\", \"\", texto)  # quitar caracteres no alfabéticos\n",
        "    return texto\n",
        "\n",
        "corpus_limpio = [limpiar_texto(t) for t in corpus]\n",
        "\n",
        "# 3. División en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(corpus_limpio, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Definición del pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"vectorizador\", TfidfVectorizer()),              # Tokenización + embeddings TF-IDF\n",
        "    (\"clasificador\", LogisticRegression())            # Clasificador\n",
        "])\n",
        "\n",
        "# 5. Entrenamiento\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Validación\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Reporte de clasificación:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"negativo\",\"positivo\"]))\n",
        "print(\"Matriz de confusión:\\n\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados\n",
        "\n",
        "* Precisión (precision): mide qué porcentaje de las predicciones positivas (o negativas) fueron correctas. Aquí, el modelo clasificó sin errores, por eso es 1.00 (100 %).\n",
        "\n",
        "* Cobertura (recall): mide qué porcentaje de los casos reales positivos (o negativos) fueron detectados correctamente. También es 100 %.\n",
        "\n",
        "* F1-score: combina precisión y recall en una sola métrica. Si ambas son perfectas, el F1 también lo es (1.00).\n",
        "\n",
        "* Support: indica cuántos ejemplos reales había en cada clase (en este caso, 1 negativo y 1 positivo en la prueba).\n",
        "\n",
        "* Accuracy global: El modelo clasificó correctamente todos los ejemplos del conjunto de prueba.\n",
        "\n",
        "# Matriz de confusión\n",
        "\n",
        "* La primera fila representa los ejemplos de la clase negativo: 1 fue correctamente clasificado como negativo (columna izquierda) y 0 se confundió con positivo.\n",
        "\n",
        "* La segunda fila representa los ejemplos de la clase positivo: 1 fue correctamente clasificado como positivo y 0 se confundió con negativo.\n",
        "\n",
        "**Resultado**: no hubo errores de clasificación.\n",
        "\n",
        "## Conclusiones\n",
        "\n",
        "* El pipeline funcionó correctamente y detectó las clases con precisión perfecta en este mini corpus.\n",
        "\n",
        "* Sin embargo, esto ocurre porque el conjunto de datos era muy pequeño y sencillo (solo 6 frases en total).\n",
        "\n",
        "* En un escenario real, con corpus más grandes y variados, no se obtendrían métricas tan perfectas. El modelo tendría que aprender a manejar frases más complejas, sarcasmos, abreviaciones o errores de escritura."
      ],
      "metadata": {
        "id": "UlKg81FR6Bnl"
      }
    }
  ]
}